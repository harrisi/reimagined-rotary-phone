Would chunking be effective for low-memory low-disk usage?
  Probably not - for any searches, the entire file needs to be searched in
  the worsy case scenario. Or I could just plan for the best or average
  case.

How to structure the file
  song;artists;min;sec;album
  How to search? What algorithm? A sorted array would lend itself well to a
  binary search, but does the cost of maintaining the sorted array force a
  different approach?

Look into vim's .swp file
  Could it be useful to save deltas of updates that would live in memory
  into the .swp file so that in the occurance of a crash, it could at least
  prompt the user at the next run that there was an error and ask if they
  want to attempt to fix the issue (possibly show a line by line update of
  what's happening, by making the .diff slightly nicer).

Can `diff` keep things in order?
  Would the cost of maintaining an ordered array be so high it wouldn't
  justify the use of a sorted array for use of quick binary search?

Fix reading in a file
  Currently the final record needs an delimeter as well, which means the case
  of a new item is signified by two delimiters (delim + '\n'), but the newline
  can be sufficient information for a new record. I just need to figure out how
  to read until a newline or semicolon.
    I think I could just change the delimeter in the FSM, but this seems messy.
    Alternatively I could just unget some chars until the newline. I don't know
    how slow this would be, though.

Regex/predicate search
  By default, search all fields (artist, album, title). This would require
  an exact match, which I don't like. At the very least I will probably
  lowercase. I could also tokenize on ':' and have the option to format query
  like "artist: some artist" to search only for artist field.
  I also would like to have the ability to search for song duration:
  "time: > 4:20" would return all songs that have a duration greater than
  4:20. This would be rather difficult, but would be super cool, I think.

Full parser
  Implementing a lower-level parser that reads character by character and can be
  given a grammar would be really cool. I know basically nothing about this,
  though, so it might be too much to implement over the weekend. It would be
  used for reading data in from the file, reading time in a nicer way, as well
  as search.
    "... given a grammar ..." perhaps more realisitcally, be given a _context_,
    i.e., 'search' or 'file' or 'time' or something of the sort. This would
    dictate how it would actually parse text.
